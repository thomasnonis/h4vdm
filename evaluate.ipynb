{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from math import floor\n",
    "import copy\n",
    "import torch\n",
    "import wandb as wb\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import auc, f1_score, roc_curve\n",
    "from packages.video_utils import H264Extractor, Video\n",
    "from packages.constants import GOP_SIZE, FRAME_HEIGHT, FRAME_WIDTH, DATASET_ROOT, N_GOPS_FROM_DIFFERENT_DEVICE, N_GOPS_FROM_SAME_DEVICE, SAME_DEVICE_LABEL\n",
    "from packages.dataset import VisionGOPDataset, GopPairDataset\n",
    "from packages.common import create_custom_logger\n",
    "from packages.network import H4vdmNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h4vdm.ipynb - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(DATASET_ROOT):\n",
    "    raise Exception(f'Dataset root does not exist: {DATASET_ROOT}')\n",
    "\n",
    "log = create_custom_logger('h4vdm.ipynb')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log.info(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GOP dataset\n",
    "\n",
    "Remember to delete dataset.json if you want to add new devices/videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h4vdm.ipynb - INFO - Dataset was loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 1914\n"
     ]
    }
   ],
   "source": [
    "bin_path = os.path.abspath(os.path.join(os.getcwd(), 'h264-extractor', 'bin'))\n",
    "h264_ext_bin = os.path.join(bin_path, 'h264dec_ext_info')\n",
    "h264_extractor = H264Extractor(bin_filename=h264_ext_bin, cache_dir=DATASET_ROOT)\n",
    "Video.set_h264_extractor(h264_extractor)\n",
    "\n",
    "vision_gop_dataset = VisionGOPDataset(\n",
    "    root_path=DATASET_ROOT,\n",
    "    devices=[],\n",
    "    media_types = ['videos'],\n",
    "    properties=[],\n",
    "    extensions=['mp4', 'mov', '3gp'],\n",
    "    gop_size=GOP_SIZE,\n",
    "    frame_width=FRAME_WIDTH,\n",
    "    frame_height=FRAME_HEIGHT,\n",
    "    gops_per_video=4,\n",
    "    build_on_init=False,\n",
    "    force_rebuild=False,\n",
    "    download_on_init=False,\n",
    "    ignore_local_dataset=False,\n",
    "    shuffle=False)\n",
    "\n",
    "is_loaded = vision_gop_dataset.load()\n",
    "if not is_loaded:\n",
    "    log.info('Dataset was not loaded. Building...')\n",
    "else:\n",
    "    log.info('Dataset was loaded.')\n",
    "\n",
    "print(f'Dataset length: {len(vision_gop_dataset)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 devices: ['D01_Samsung_GalaxyS3Mini', 'D02_Apple_iPhone4s', 'D03_Huawei_P9', 'D04_LG_D290', 'D05_Apple_iPhone5c', 'D06_Apple_iPhone6', 'D07_Lenovo_P70A', 'D08_Samsung_GalaxyTab3', 'D09_Apple_iPhone4', 'D10_Apple_iPhone4s', 'D11_Samsung_GalaxyS3', 'D12_Sony_XperiaZ1Compact', 'D13_Apple_iPad2', 'D14_Apple_iPhone5c', 'D15_Apple_iPhone6', 'D16_Huawei_P9Lite', 'D17_Microsoft_Lumia640LTE', 'D18_Apple_iPhone5c', 'D19_Apple_iPhone6Plus', 'D20_Apple_iPadMini', 'D21_Wiko_Ridge4G', 'D22_Samsung_GalaxyTrendPlus', 'D23_Asus_Zenfone2Laser', 'D24_Xiaomi_RedmiNote3', 'D25_OnePlus_A3000', 'D26_Samsung_GalaxyS3Mini', 'D27_Samsung_GalaxyS5', 'D28_Huawei_P8', 'D29_Apple_iPhone5', 'D30_Huawei_Honor5c', 'D31_Samsung_GalaxyS4Mini', 'D32_OnePlus_A3003', 'D33_Huawei_Ascend', 'D34_Apple_iPhone5', 'D35_Samsung_GalaxyTabA']\n",
      "Training set 1 devices: 25, 15, 19, 10, 07, 35, 01, 21, 29, 30, 04, 20, 34, 03, 16, 23, 31, 14, \n",
      "Testing set 1 devices: 18, 13, 28, 26, 02, 32, 09, 24, 22, 05, 27, 06, 17, 33, 11, 08, 12, \n",
      "Training set 2 devices: 14, 11, 29, 01, 31, 17, 25, 08, 26, 02, 19, 10, 32, 07, 05, 04, 28, 23, \n",
      "Testing set 2 devices: 18, 27, 15, 12, 30, 33, 35, 34, 24, 06, 22, 20, 13, 09, 03, 21, 16, \n",
      "Training set 3 devices: 20, 24, 01, 09, 21, 11, 33, 03, 13, 10, 06, 31, 34, 08, 07, 28, 23, 15, \n",
      "Testing set 3 devices: 26, 32, 14, 27, 05, 17, 22, 19, 02, 30, 25, 12, 04, 29, 18, 35, 16, \n",
      "Training set 4 devices: 10, 01, 04, 07, 29, 30, 28, 08, 05, 09, 21, 35, 20, 17, 23, 14, 19, 18, \n",
      "Testing set 4 devices: 11, 12, 26, 15, 32, 03, 13, 27, 33, 22, 34, 31, 25, 24, 06, 16, 02, \n",
      "Training set 5 devices: 35, 11, 07, 22, 17, 33, 18, 13, 25, 09, 34, 24, 03, 23, 20, 12, 02, 04, 26, 01, 27, 06, 05, 30, \n",
      "Testing set 5 devices: 14, 15, 21, 19, 16, 08, 32, 29, 31, 28, 10, \n",
      "Training set 6 devices: 14, 15, 21, 19, 16, 08, 32, 29, 31, 28, 10, 24, 03, 23, 20, 12, 02, 04, 26, 01, 27, 06, 05, 30, \n",
      "Testing set 6 devices: 35, 11, 07, 22, 17, 33, 18, 13, 25, 09, 34, \n",
      "Training set 7 devices: 14, 15, 21, 19, 16, 08, 32, 29, 31, 28, 10, 35, 11, 07, 22, 17, 33, 18, 13, 25, 09, 34, \n",
      "Testing set 7 devices: 24, 03, 23, 20, 12, 02, 04, 26, 01, 27, 06, 05, 30, \n"
     ]
    }
   ],
   "source": [
    "devices = ['D01_Samsung_GalaxyS3Mini', 'D02_Apple_iPhone4s', 'D03_Huawei_P9', 'D04_LG_D290', 'D05_Apple_iPhone5c', 'D06_Apple_iPhone6', 'D07_Lenovo_P70A', 'D08_Samsung_GalaxyTab3', 'D09_Apple_iPhone4', 'D10_Apple_iPhone4s', 'D11_Samsung_GalaxyS3', 'D12_Sony_XperiaZ1Compact', 'D13_Apple_iPad2', 'D14_Apple_iPhone5c', 'D15_Apple_iPhone6', 'D16_Huawei_P9Lite', 'D17_Microsoft_Lumia640LTE', 'D18_Apple_iPhone5c', 'D19_Apple_iPhone6Plus', 'D20_Apple_iPadMini', 'D21_Wiko_Ridge4G', 'D22_Samsung_GalaxyTrendPlus', 'D23_Asus_Zenfone2Laser', 'D24_Xiaomi_RedmiNote3', 'D25_OnePlus_A3000', 'D26_Samsung_GalaxyS3Mini', 'D27_Samsung_GalaxyS5', 'D28_Huawei_P8', 'D29_Apple_iPhone5', 'D30_Huawei_Honor5c', 'D31_Samsung_GalaxyS4Mini', 'D32_OnePlus_A3003', 'D33_Huawei_Ascend', 'D34_Apple_iPhone5', 'D35_Samsung_GalaxyTabA']\n",
    "\n",
    "print(f'{len(devices)} devices: {devices}')\n",
    "\n",
    "training_set_1_devices = ['D25_OnePlus_A3000', 'D15_Apple_iPhone6', 'D19_Apple_iPhone6Plus', 'D10_Apple_iPhone4s', 'D07_Lenovo_P70A', 'D35_Samsung_GalaxyTabA', 'D01_Samsung_GalaxyS3Mini', 'D21_Wiko_Ridge4G', 'D29_Apple_iPhone5', 'D30_Huawei_Honor5c', 'D04_LG_D290', 'D20_Apple_iPadMini', 'D34_Apple_iPhone5', 'D03_Huawei_P9', 'D16_Huawei_P9Lite', 'D23_Asus_Zenfone2Laser', 'D31_Samsung_GalaxyS4Mini', 'D14_Apple_iPhone5c']\n",
    "testing_set_1_devices = ['D18_Apple_iPhone5c', 'D13_Apple_iPad2', 'D28_Huawei_P8', 'D26_Samsung_GalaxyS3Mini', 'D02_Apple_iPhone4s', 'D32_OnePlus_A3003', 'D09_Apple_iPhone4', 'D24_Xiaomi_RedmiNote3', 'D22_Samsung_GalaxyTrendPlus', 'D05_Apple_iPhone5c', 'D27_Samsung_GalaxyS5', 'D06_Apple_iPhone6', 'D17_Microsoft_Lumia640LTE', 'D33_Huawei_Ascend', 'D11_Samsung_GalaxyS3', 'D08_Samsung_GalaxyTab3', 'D12_Sony_XperiaZ1Compact']\n",
    "\n",
    "training_set_2_devices = ['D14_Apple_iPhone5c', 'D11_Samsung_GalaxyS3', 'D29_Apple_iPhone5', 'D01_Samsung_GalaxyS3Mini', 'D31_Samsung_GalaxyS4Mini', 'D17_Microsoft_Lumia640LTE', 'D25_OnePlus_A3000', 'D08_Samsung_GalaxyTab3', 'D26_Samsung_GalaxyS3Mini', 'D02_Apple_iPhone4s', 'D19_Apple_iPhone6Plus', 'D10_Apple_iPhone4s', 'D32_OnePlus_A3003', 'D07_Lenovo_P70A', 'D05_Apple_iPhone5c', 'D04_LG_D290', 'D28_Huawei_P8', 'D23_Asus_Zenfone2Laser']\n",
    "testing_set_2_devices = ['D18_Apple_iPhone5c', 'D27_Samsung_GalaxyS5', 'D15_Apple_iPhone6', 'D12_Sony_XperiaZ1Compact', 'D30_Huawei_Honor5c', 'D33_Huawei_Ascend', 'D35_Samsung_GalaxyTabA', 'D34_Apple_iPhone5', 'D24_Xiaomi_RedmiNote3', 'D06_Apple_iPhone6', 'D22_Samsung_GalaxyTrendPlus', 'D20_Apple_iPadMini', 'D13_Apple_iPad2', 'D09_Apple_iPhone4', 'D03_Huawei_P9', 'D21_Wiko_Ridge4G', 'D16_Huawei_P9Lite']\n",
    "\n",
    "training_set_3_devices = ['D20_Apple_iPadMini', 'D24_Xiaomi_RedmiNote3', 'D01_Samsung_GalaxyS3Mini', 'D09_Apple_iPhone4', 'D21_Wiko_Ridge4G', 'D11_Samsung_GalaxyS3', 'D33_Huawei_Ascend', 'D03_Huawei_P9', 'D13_Apple_iPad2', 'D10_Apple_iPhone4s', 'D06_Apple_iPhone6', 'D31_Samsung_GalaxyS4Mini', 'D34_Apple_iPhone5', 'D08_Samsung_GalaxyTab3', 'D07_Lenovo_P70A', 'D28_Huawei_P8', 'D23_Asus_Zenfone2Laser', 'D15_Apple_iPhone6']\n",
    "testing_set_3_devices = ['D26_Samsung_GalaxyS3Mini', 'D32_OnePlus_A3003', 'D14_Apple_iPhone5c', 'D27_Samsung_GalaxyS5', 'D05_Apple_iPhone5c', 'D17_Microsoft_Lumia640LTE', 'D22_Samsung_GalaxyTrendPlus', 'D19_Apple_iPhone6Plus', 'D02_Apple_iPhone4s', 'D30_Huawei_Honor5c', 'D25_OnePlus_A3000', 'D12_Sony_XperiaZ1Compact', 'D04_LG_D290', 'D29_Apple_iPhone5', 'D18_Apple_iPhone5c', 'D35_Samsung_GalaxyTabA', 'D16_Huawei_P9Lite']\n",
    "\n",
    "training_set_4_devices = ['D10_Apple_iPhone4s', 'D01_Samsung_GalaxyS3Mini', 'D04_LG_D290', 'D07_Lenovo_P70A', 'D29_Apple_iPhone5', 'D30_Huawei_Honor5c', 'D28_Huawei_P8', 'D08_Samsung_GalaxyTab3', 'D05_Apple_iPhone5c', 'D09_Apple_iPhone4', 'D21_Wiko_Ridge4G', 'D35_Samsung_GalaxyTabA', 'D20_Apple_iPadMini', 'D17_Microsoft_Lumia640LTE', 'D23_Asus_Zenfone2Laser', 'D14_Apple_iPhone5c', 'D19_Apple_iPhone6Plus', 'D18_Apple_iPhone5c']\n",
    "testing_set_4_devices = ['D11_Samsung_GalaxyS3', 'D12_Sony_XperiaZ1Compact', 'D26_Samsung_GalaxyS3Mini', 'D15_Apple_iPhone6', 'D32_OnePlus_A3003', 'D03_Huawei_P9', 'D13_Apple_iPad2', 'D27_Samsung_GalaxyS5', 'D33_Huawei_Ascend', 'D22_Samsung_GalaxyTrendPlus', 'D34_Apple_iPhone5', 'D31_Samsung_GalaxyS4Mini', 'D25_OnePlus_A3000', 'D24_Xiaomi_RedmiNote3', 'D06_Apple_iPhone6', 'D16_Huawei_P9Lite', 'D02_Apple_iPhone4s']\n",
    "\n",
    "training_set_5_devices = ['D35_Samsung_GalaxyTabA', 'D11_Samsung_GalaxyS3', 'D07_Lenovo_P70A', 'D22_Samsung_GalaxyTrendPlus', 'D17_Microsoft_Lumia640LTE', 'D33_Huawei_Ascend', 'D18_Apple_iPhone5c', 'D13_Apple_iPad2', 'D25_OnePlus_A3000', 'D09_Apple_iPhone4', 'D34_Apple_iPhone5', 'D24_Xiaomi_RedmiNote3', 'D03_Huawei_P9', 'D23_Asus_Zenfone2Laser', 'D20_Apple_iPadMini', 'D12_Sony_XperiaZ1Compact', 'D02_Apple_iPhone4s', 'D04_LG_D290', 'D26_Samsung_GalaxyS3Mini', 'D01_Samsung_GalaxyS3Mini', 'D27_Samsung_GalaxyS5', 'D06_Apple_iPhone6', 'D05_Apple_iPhone5c', 'D30_Huawei_Honor5c']\n",
    "testing_set_5_devices = ['D14_Apple_iPhone5c', 'D15_Apple_iPhone6', 'D21_Wiko_Ridge4G', 'D19_Apple_iPhone6Plus', 'D16_Huawei_P9Lite', 'D08_Samsung_GalaxyTab3', 'D32_OnePlus_A3003', 'D29_Apple_iPhone5', 'D31_Samsung_GalaxyS4Mini', 'D28_Huawei_P8', 'D10_Apple_iPhone4s']\n",
    "\n",
    "training_set_6_devices = ['D14_Apple_iPhone5c', 'D15_Apple_iPhone6', 'D21_Wiko_Ridge4G', 'D19_Apple_iPhone6Plus', 'D16_Huawei_P9Lite', 'D08_Samsung_GalaxyTab3', 'D32_OnePlus_A3003', 'D29_Apple_iPhone5', 'D31_Samsung_GalaxyS4Mini', 'D28_Huawei_P8', 'D10_Apple_iPhone4s', 'D24_Xiaomi_RedmiNote3', 'D03_Huawei_P9', 'D23_Asus_Zenfone2Laser', 'D20_Apple_iPadMini', 'D12_Sony_XperiaZ1Compact', 'D02_Apple_iPhone4s', 'D04_LG_D290', 'D26_Samsung_GalaxyS3Mini', 'D01_Samsung_GalaxyS3Mini', 'D27_Samsung_GalaxyS5', 'D06_Apple_iPhone6', 'D05_Apple_iPhone5c', 'D30_Huawei_Honor5c']\n",
    "testing_set_6_devices = ['D35_Samsung_GalaxyTabA', 'D11_Samsung_GalaxyS3', 'D07_Lenovo_P70A', 'D22_Samsung_GalaxyTrendPlus', 'D17_Microsoft_Lumia640LTE', 'D33_Huawei_Ascend', 'D18_Apple_iPhone5c', 'D13_Apple_iPad2', 'D25_OnePlus_A3000', 'D09_Apple_iPhone4', 'D34_Apple_iPhone5']\n",
    "\n",
    "training_set_7_devices = ['D14_Apple_iPhone5c', 'D15_Apple_iPhone6', 'D21_Wiko_Ridge4G', 'D19_Apple_iPhone6Plus', 'D16_Huawei_P9Lite', 'D08_Samsung_GalaxyTab3', 'D32_OnePlus_A3003', 'D29_Apple_iPhone5', 'D31_Samsung_GalaxyS4Mini', 'D28_Huawei_P8', 'D10_Apple_iPhone4s', 'D35_Samsung_GalaxyTabA', 'D11_Samsung_GalaxyS3', 'D07_Lenovo_P70A', 'D22_Samsung_GalaxyTrendPlus', 'D17_Microsoft_Lumia640LTE', 'D33_Huawei_Ascend', 'D18_Apple_iPhone5c', 'D13_Apple_iPad2', 'D25_OnePlus_A3000', 'D09_Apple_iPhone4', 'D34_Apple_iPhone5']\n",
    "testing_set_7_devices = ['D24_Xiaomi_RedmiNote3', 'D03_Huawei_P9', 'D23_Asus_Zenfone2Laser', 'D20_Apple_iPadMini', 'D12_Sony_XperiaZ1Compact', 'D02_Apple_iPhone4s', 'D04_LG_D290', 'D26_Samsung_GalaxyS3Mini', 'D01_Samsung_GalaxyS3Mini', 'D27_Samsung_GalaxyS5', 'D06_Apple_iPhone6', 'D05_Apple_iPhone5c', 'D30_Huawei_Honor5c']\n",
    "\n",
    "training_set_devices = [training_set_1_devices, training_set_2_devices, training_set_3_devices, training_set_4_devices, training_set_5_devices, training_set_6_devices, training_set_7_devices]\n",
    "testing_set_devices = [testing_set_1_devices, testing_set_2_devices, testing_set_3_devices, testing_set_4_devices, testing_set_5_devices, testing_set_6_devices, testing_set_7_devices]\n",
    "\n",
    "# training_set_devices = [training_set_1_devices]\n",
    "# testing_set_devices = [testing_set_1_devices]\n",
    "\n",
    "assert len(training_set_devices) == len(testing_set_devices), 'There must be the same number of training and testing sets'\n",
    "n_datasets = len(training_set_devices)\n",
    "\n",
    "for epoch in range(n_datasets):\n",
    "    # print(f'Training set {epoch+1} devices: {training_set_devices[epoch]}')\n",
    "    # print(f'Testing set {epoch+1} devices: {testing_set_devices[epoch]}')\n",
    "    print(f'Training set {epoch+1} devices: ', end='')\n",
    "    for name in training_set_devices[epoch]:\n",
    "        print(f'{name[1:3]}, ', end='')\n",
    "    print('')\n",
    "    print(f'Testing set {epoch+1} devices: ', end='')\n",
    "    for name in testing_set_devices[epoch]:\n",
    "        print(f'{name[1:3]}, ', end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_PERCENTAGE = 12.5 # 1/8\n",
    "TEST_PERCENTAGE = 40\n",
    "\n",
    "# define loss function\n",
    "compute_loss = torch.nn.BCELoss()\n",
    "\n",
    "# instantiate the model\n",
    "# net = H4vdmNet()\n",
    "net = torch.load('models/2024-03-10_02:17_h4vdm.pth')\n",
    "net = net.to(device)\n",
    "\n",
    "def compute_similarity(gop1_features, gop2_features):\n",
    "    diff = torch.subtract(gop1_features, gop2_features)\n",
    "    norm = torch.norm(diff, 2)\n",
    "    tanh = torch.tanh(norm)\n",
    "    return (torch.ones(tanh.shape) - tanh)\n",
    "\n",
    "def validate_one_step(model, gop1, gop2, label):\n",
    "    gop1_features = model(gop1, debug=False, device=device)\n",
    "    gop2_features = model(gop2, debug=False, device=device)\n",
    "    gop1_features = gop1_features.to(device)\n",
    "    gop2_features = gop2_features.to(device)\n",
    "\n",
    "    similarity = compute_similarity(gop1_features, gop2_features).double()\n",
    "    similarity.to(device)\n",
    "    \n",
    "    label = torch.tensor(label, dtype=float, requires_grad=False, device=device)\n",
    "    label = label.double()\n",
    "    \n",
    "    loss = compute_loss(similarity, label)\n",
    "\n",
    "    return loss, label, similarity\n",
    "\n",
    "def validate_one_epoch(model, devices):\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    similarities = []\n",
    "    for i, testing_set_devices in enumerate(devices):\n",
    "        print(f'Loading validation set {i+1}/{len(devices)}')\n",
    "        testing_set = GopPairDataset(vision_gop_dataset, N_GOPS_FROM_SAME_DEVICE, N_GOPS_FROM_DIFFERENT_DEVICE, consider_devices=testing_set_devices, shuffle=True)\n",
    "        testing_set.pair_dataset = testing_set.pair_dataset[:floor(len(testing_set)*(1-TEST_PERCENTAGE/100))] # reduce size by removing TEST_PERCENTAGE % of the dataset\n",
    "        validation_set = copy.deepcopy(testing_set)\n",
    "        validation_set.pair_dataset = validation_set.pair_dataset[:floor(len(testing_set)*(1-VALIDATION_PERCENTAGE/100))] # VALIDATION_PERCENTAGE % of the training set is used for validation, works because the dataset is shuffled\n",
    "        testing_set.pair_dataset = testing_set.pair_dataset[floor(len(testing_set)*(1-VALIDATION_PERCENTAGE/100)):]\n",
    "        \n",
    "        print(f'Validating batch {i+1}/{len(devices)}')\n",
    "        for j in range(len(testing_set)):\n",
    "            gop1, gop2, label = testing_set[j]\n",
    "            loss, label, similarity = validate_one_step(model, gop1, gop2, label)\n",
    "            labels.append(label.item())\n",
    "            similarities.append(similarity.item())\n",
    "\n",
    "    return labels, similarities\n",
    "\n",
    "def compute_ROC(scores, labels, show: bool = True):\n",
    "    # compute ROC\n",
    "    fpr, tpr, thresholds = roc_curve(np.asarray(labels), np.asarray(scores), drop_intermediate=False)\n",
    "    # compute AUC\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    tnr = 1 - fpr\n",
    "    max_index = np.argmax(tpr + tnr)\n",
    "\n",
    "    threshold = thresholds[max_index]\n",
    "    chosen_tpr = tpr[max_index]\n",
    "    chosen_fpr = fpr[max_index]\n",
    "\n",
    "\n",
    "    if show is True:\n",
    "        lw = 2\n",
    "        plt.figure()\n",
    "        plt.title('Receiver Operating Characteristic (ROC)')\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC (AUC = %0.2f)' % (roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "        plt.plot(chosen_fpr, chosen_tpr, 'o', markersize=10, alpha=0.5, label=\"Threshold = %0.2f\" % threshold)\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    return threshold, chosen_tpr, chosen_fpr, roc_auc\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(scores, labels, threshold):\n",
    "    thresholded_scores = scores > threshold\n",
    "\n",
    "    precision = precision_score(labels, thresholded_scores, average='macro')\n",
    "    recall = recall_score(labels, thresholded_scores, average='macro')\n",
    "    f1 = f1_score(labels, thresholded_scores, average='macro')\n",
    "    accuracy = accuracy_score(labels, thresholded_scores)\n",
    "\n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation set 1/7\n",
      "Testing set has 459 GOP pairs\n",
      "Validation set has 3213 GOP pairs\n",
      "Validating batch 1/7\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "labels, similarities = validate_one_epoch(net, testing_set_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true takes value in {} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m threshold, tpr, fpr, roc_auc \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ROC\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimilarities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m precision, recall, f1, accuracy \u001b[38;5;241m=\u001b[39m compute_metrics(similarities, labels, threshold)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 61\u001b[0m, in \u001b[0;36mcompute_ROC\u001b[0;34m(scores, labels, show)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_ROC\u001b[39m(scores, labels, show: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# compute ROC\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_intermediate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# compute AUC\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n",
      "File \u001b[0;32m~/Documents/uni/h4vdm/.env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/uni/h4vdm/.env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1108\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1007\u001b[0m     {\n\u001b[1;32m   1008\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m ):\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/uni/h4vdm/.env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:834\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    831\u001b[0m     y_score \u001b[38;5;241m=\u001b[39m y_score[nonzero_weight_mask]\n\u001b[1;32m    832\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight[nonzero_weight_mask]\n\u001b[0;32m--> 834\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[43m_check_pos_label_consistency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# make y_true a boolean vector\u001b[39;00m\n\u001b[1;32m    837\u001b[0m y_true \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m==\u001b[39m pos_label\n",
      "File \u001b[0;32m~/Documents/uni/h4vdm/.env/lib/python3.10/site-packages/sklearn/utils/validation.py:2454\u001b[0m, in \u001b[0;36m_check_pos_label_consistency\u001b[0;34m(pos_label, y_true)\u001b[0m\n\u001b[1;32m   2443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   2444\u001b[0m     classes\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2445\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2451\u001b[0m     )\n\u001b[1;32m   2452\u001b[0m ):\n\u001b[1;32m   2453\u001b[0m     classes_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m classes\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[0;32m-> 2454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2455\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true takes value in \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclasses_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m and pos_label is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified: either make y_true take value in \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0, 1} or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m-1, 1} or pass pos_label explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2458\u001b[0m     )\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2460\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: y_true takes value in {} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly."
     ]
    }
   ],
   "source": [
    "threshold, tpr, fpr, roc_auc = compute_ROC(similarities, labels)\n",
    "precision, recall, f1, accuracy = compute_metrics(similarities, labels, threshold)\n",
    "\n",
    "print(f'Precision: {precision:.2%}')\n",
    "print(f'Recall: {recall:.2%}')\n",
    "print(f'F1: {f1:.2%}')\n",
    "print(f'Accuracy: {accuracy:.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
